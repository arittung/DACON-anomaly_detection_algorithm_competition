{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba63836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm\n",
    "from imblearn.combine import *\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "import time\n",
    "\n",
    "from PIL import ImageFile \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215db17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_plot(y): \n",
    "    counter = Counter(y)\n",
    "    print(counter)\n",
    "    for k,v in counter.items():\n",
    "        print('Class=%s, n=%d (%.3f%%)' % (k, v, v / len(y) * 100))\n",
    "    plt.bar(counter.keys(), counter.values())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99ab409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf5a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(img, set_size):\n",
    "\n",
    "    h, w, c = img.shape\n",
    "\n",
    "    if set_size > min(h, w):\n",
    "        return img\n",
    "\n",
    "    crop_width = set_size\n",
    "    crop_height = set_size\n",
    "\n",
    "    mid_x, mid_y = w//2, h//2\n",
    "    offset_x, offset_y = crop_width//2, crop_height//2\n",
    "       \n",
    "    crop_img = img[mid_y - offset_y:mid_y + offset_y, mid_x - offset_x:mid_x + offset_x]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ef5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(path):\n",
    "    # data load\n",
    "    train_df = pd.read_csv(path)\n",
    "    labelList = train_df['label'].unique()\n",
    "    label = train_df['label'].to_list()\n",
    "    \n",
    "    for i in range(len(labelList)):\n",
    "        folderpath = './train_data/' + labelList[i]\n",
    "        createFolder(folderpath)\n",
    "        # ./train_data/transistor-good \n",
    "        # ./train_data/capsule-good\n",
    "        # ./train_data/wood-good\n",
    "    \n",
    "    # label별로 파일 구분하여 넣어놓기\n",
    "    for i in range(len(train_df)):\n",
    "        src_path = './data/train/'\n",
    "        dst_path = './train_data/'\n",
    "        filenum = i + 10000\n",
    "        filename = str(filenum)+'.png'\n",
    "        \n",
    "        src_path += filename\n",
    "        dst_path += label[i]\n",
    "        \n",
    "        shutil.copy(src_path, dst_path)\n",
    "        # ./data/train/10000.png ./train_data/transistor-good\n",
    "        #./data/train/10001.png ./train_data/capsule-good\n",
    "        \n",
    "    # preprocessing\n",
    "    labelCount = train_df[['class', 'label']].groupby('label').count().rename(columns={'class': 'count'})\n",
    "\n",
    "    # 기존 라벨별 이미지 개수 \n",
    "    origin_datanum = labelCount['count'].tolist()\n",
    "    # 10, 11, 11, 209, 7, 6, 6, 7, 5, 224,...\n",
    "        \n",
    "    data = train_df.values\n",
    "    X, y = data[:, 1], data[:, -1]\n",
    "    for i in range(len(X)):\n",
    "            X[i] = X[i][:5]\n",
    "\n",
    "    X = np.array(X, dtype = np.float64)\n",
    "    X = X.reshape((4277, 1))\n",
    "\n",
    "    count_and_plot(y)\n",
    "\n",
    "    #   oversampling 시작\n",
    "    X_resampled, y_resampled = SMOTETomek(random_state=0, smote = SMOTE(k_neighbors=3)).fit_resample(X, y)\n",
    "    count_and_plot(y_resampled)\n",
    "    #print(y_sap)\n",
    "        \n",
    "    # oversampled 된 label과 file_name dataframe으로 묶음\n",
    "    y_resampled2 = y_resampled.reshape((y_resampled.size, 1))\n",
    "    Xy = np.concatenate((X_resampled, y_resampled2), axis =1)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(Xy)\n",
    "    df.to_csv('smotetomek_result.csv', index=False)\n",
    "    \n",
    "    \n",
    "    train_df2 = pd.DataFrame(Xy)\n",
    "    augmented_filenames = train_df2[0].tolist()    \n",
    "        \n",
    "    labelCount2 = train_df2.groupby(1).count().rename(columns={'label':'count'})\n",
    "    \n",
    "    # augmentation 후 라벨별 개수 \n",
    "    oversampled_datanum = labelCount2[0].tolist()\n",
    "    # [391, 391, 391, 391, 391, 391, 391, 391,...\n",
    "    \n",
    "    #oversampling 해야 하는 개수\n",
    "    oversampling_num = [x-y for x, y in zip(oversampled_datanum,origin_datanum)]\n",
    "    print(\"oversampling 해야 하는 개수: \", oversampling_num)\n",
    "    # [381, 380, 380, 182, 384, 385, 385, 384,...\n",
    "        \n",
    "    # img augmentation\n",
    "    labelList = np.sort(labelList)\n",
    "    print(\"total num : \", len(labelList))\n",
    "    \n",
    "    for i in range(len(labelList)):# 나눈 dir 별로 각 label에 필요한 횟수 만큼 augmentation\n",
    "        \n",
    "        augmented_num = oversampling_num[i]\n",
    "        # augmentation 할 파일 경로\n",
    "        origin_file_path = './train_data/'+ labelList[i] +'/'\n",
    "        \n",
    "        # augmentated image 저장할 파일 경로\n",
    "        save_file_path = './data/train/'\n",
    "        file_names = os.listdir(origin_file_path)\n",
    "        # ['10000.png', '10002.png', '10009.png', '10042.png', '10049.png',\n",
    "        \n",
    "        \n",
    "        # 원래 label별 img\n",
    "        before = train_df[train_df['label'] == labelList[i]]\n",
    "        #  sampling 후 label별 img\n",
    "        after = train_df2[train_df2[1] == labelList[i]]\n",
    "\n",
    "        # 각 file_name의 차집합 구함\n",
    "        before = (before['file_name'].tolist())\n",
    "        for j in range(len(before)):\n",
    "            before[j] = before[j][:5]\n",
    "            \n",
    "        before = np.array(before, dtype = np.int64)\n",
    "        after = (after[0].tolist())\n",
    "\n",
    "        # before엔 있는데 after에는 없는 것들\n",
    "        sample1 = list(set(before) - set(after))\n",
    "        #print(sample1, len(sample1))\n",
    "\n",
    "        # after엔 있는데 before에는 없는 것들\n",
    "        sample2 = list(set(after) - set(before))\n",
    "        #print(sample2, len(sample2))\n",
    "        \n",
    "        for j in tqdm(range(len(sample1)), desc = \"%d : %s label's deleting process\"%(i+1, labelList[i])): # 지워진 img 파일 삭제\n",
    "            del_file_name = save_file_path +str(sample1[j])+'.png'\n",
    "        #file_names = os.listdir(origin_file_path)\n",
    "        #print(\"now files: \", len(file_names))\n",
    "            \n",
    "            #print(\"del: \", del_file_name) \n",
    "            os.remove(del_file_name)\n",
    "    \n",
    "\n",
    "        for j in tqdm(range(len(sample2)), desc = \"%d : %s label's augmentation process\"%(i+1, labelList[i])): # 새로 생긴 img 파일 생성\n",
    "\n",
    "            aug_file_name = sample2[j]\n",
    "            # augmentation 할 원본 파일 이름\n",
    "            random_file_num = random.randrange(0,len(file_names))\n",
    "            origin_file_name = file_names[random_file_num]\n",
    "            \n",
    "            image = Image.open(origin_file_path+origin_file_name)\n",
    "            random_augment = random.randrange(1,4)\n",
    "\n",
    "            if(random_augment == 1):\n",
    "                #이미지 흑백\n",
    "                convert_color_img = image.convert('L')\n",
    "                convert_color_img.save(save_file_path +str(aug_file_name)+ '.png')\n",
    "                \n",
    "            elif(random_augment == 2):\n",
    "                # center_crop\n",
    "                \n",
    "                img = cv2.imread(origin_file_path+origin_file_name)\n",
    "                img_cvt = center_crop(img, 1000)\n",
    "                cv2.imwrite(save_file_path +str(aug_file_name)+ '.png', img_cvt)\n",
    "                \n",
    "            elif(random_augment == 3):\n",
    "                # color_change\n",
    "                \n",
    "                color = [cv2.COLOR_BGR2RGB, cv2.COLOR_BGR2GRAY,\n",
    "                         cv2.COLOR_BGR2XYZ,cv2.COLOR_BGR2YCrCb, cv2.COLOR_BGR2HSV,\n",
    "                        cv2.COLOR_BGR2Lab, cv2.COLOR_BGR2Luv,cv2.COLOR_BGR2HLS,cv2.COLOR_BGR2YUV]\n",
    "                img = cv2.imread(origin_file_path+origin_file_name)\n",
    "                r = random.randrange(0, len(color))\n",
    "                \n",
    "                img_cvt = cv2.cvtColor(img, color[r])\n",
    "                cv2.imwrite(save_file_path +str(aug_file_name)+ '.png', img_cvt)    \n",
    "                \n",
    "                \n",
    "    return [X_resampled, y_resampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eaa575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921a163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f05cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좌우반전\n",
    "# print(\"invert\")\n",
    "#    inverted_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "#    inverted_image.save(save_file_path + str(aug_file_name)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a24d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#            elif(random_augment == 2):\n",
    "                #이미지 기울이기\n",
    "            #print(\"rotate\")\n",
    "#                rotated_image = image.rotate(random.randrange(-20, 20))\n",
    "#                rotated_image.save(save_file_path +str(aug_file_name)+ '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47673b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#노이즈 추가하기\n",
    "#                img = cv2.imread(origin_file_path+origin_file_name)\n",
    "            #print(\"noise\")\n",
    "#                row,col,ch= img.shape\n",
    "#                mean = 0\n",
    "#                var = 0.1\n",
    "#                sigma = var**0.5\n",
    "#                gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "#                gauss = gauss.reshape(row,col,ch)\n",
    "#                noisy_array = img + gauss\n",
    "#                noisy_image = Image.fromarray(np.uint8(noisy_array)).convert('RGB')\n",
    "#                noisy_image.save(save_file_path +str(aug_file_name)+ '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f799b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a3228cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas",
   "language": "python",
   "name": "nas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
